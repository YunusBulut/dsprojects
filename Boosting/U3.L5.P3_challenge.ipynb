{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4167</td>\n",
       "      <td>341</td>\n",
       "      <td>4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1533</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5458</td>\n",
       "      <td>1874</td>\n",
       "      <td>7332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0.0   1.0   All\n",
       "partner                  \n",
       "0.0      4167   341  4508\n",
       "1.0      1291  1533  2824\n",
       "All      5458  1874  7332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>454</td>\n",
       "      <td>51</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>151</td>\n",
       "      <td>159</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>605</td>\n",
       "      <td>210</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0.0  1.0  All\n",
       "partner               \n",
       "0.0      454   51  505\n",
       "1.0      151  159  310\n",
       "All      605  210  815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "display(table_train.head())\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "display(table_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=[15,5])\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  agea  \\\n",
       "0    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0  60.0   \n",
       "1    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0  59.0   \n",
       "\n",
       "   partner  \n",
       "0      1.0  \n",
       "1      1.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = df.drop(['idno', 'cntry', 'year'], axis=1)\n",
    "dfn.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt with only the best 5 features listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "\n",
    "\n",
    "def train_and_score(X=None, Y=None, testpct=.1):\n",
    "    offset = int(X.shape[0] * (1-testpct))\n",
    "    X_train, y_train = X[:offset], y[:offset]\n",
    "    X_test, y_test = X[offset:], y[offset:]\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "    # Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['agea', 'happy', 'gndr', 'sclmeet', 'tvtot']\n",
    "X = df[features]\n",
    "Y = df['partner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04896344789961811\n",
      "Percent Type II errors: 0.1815330060010911\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05766871165644172\n",
      "Percent Type II errors: 0.2\n"
     ]
    }
   ],
   "source": [
    "train_and_score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03879204517554628\n",
      "Percent Type II errors: 0.18119322366805793\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05768286696121748\n",
      "Percent Type II errors: 0.19342169857633776\n"
     ]
    }
   ],
   "source": [
    "train_and_score(X,Y,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03879204517554628\n",
      "Percent Type II errors: 0.18119322366805793\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05768286696121748\n",
      "Percent Type II errors: 0.19342169857633776\n"
     ]
    }
   ],
   "source": [
    "#Not real different. Try with more depth\n",
    "def get_params():\n",
    "    params = {'n_estimators': 500,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "    return params\n",
    "\n",
    "train_and_score(X,Y,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not a good idea, let's set that back and try more estimators\n",
    "def get_params():\n",
    "    params = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03879204517554628\n",
      "Percent Type II errors: 0.18119322366805793\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05768286696121748\n",
      "Percent Type II errors: 0.19342169857633776\n"
     ]
    }
   ],
   "source": [
    "train_and_score(X,Y, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With these features, there's not much more info to learn.\n",
    "#Let's see what lasso has to say"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03952860299533514\n",
      "Percent Type II errors: 0.17358212619690647\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.062346588119784\n",
      "Percent Type II errors: 0.19170348551791852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "Y = df['partner'] -1\n",
    "\n",
    "train_and_score(X,Y, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just for fun: 0.7202453987730061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\greg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02308615, -0.0266323 ,  0.00819386,  0.03104319, -0.23076077,\n",
       "         0.24779459, -0.00445327,  0.16367796, -0.02916152]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso = LogisticRegression(penalty='l1', C=1)\n",
    "\n",
    "offset = int(X.shape[0] * (.9))\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "lassofit = lasso.fit(X_train, y_train)\n",
    "print(\"Just for fun:\", lassofit.score(X_test, y_test))\n",
    "\n",
    "\n",
    "display(lassofit.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso didn't remove any. \n",
    "#Instead, let's set up a loop. Each pass fits and scores a model, then removes the least important feature until the dataframe\n",
    "#only has one column left\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.051320193380438826\n",
      "Percent Type II errors: 0.2026775753068055\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.05764224618817404\n",
      "Percent Type II errors: 0.1885459278542209\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.05355150613611008\n",
      "Percent Type II errors: 0.19003346969133506\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.06284864261807363\n",
      "Percent Type II errors: 0.1911491260691707\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.0572703607288955\n",
      "Percent Type II errors: 0.1911491260691707\n",
      "\n",
      "Features:  ['happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.05280773521755299\n",
      "Percent Type II errors: 0.189289698772778\n",
      "\n",
      "Features:  ['happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.056154704351059875\n",
      "Percent Type II errors: 0.19709929341762736\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.04834510970621049\n",
      "Percent Type II errors: 0.20007437709185572\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.046113796950539236\n",
      "Percent Type II errors: 0.21457791000371884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.10821866865005578\n",
      "Percent Type II errors: 0.18073633320937152\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'agea']\n",
      "Percent Type I errors: 0.11082186686500557\n",
      "Percent Type II errors: 0.1833395314243213\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.09594644849386388\n",
      "Percent Type II errors: 0.18668650055782818\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.09408702119747119\n",
      "Percent Type II errors: 0.17664559315730755\n",
      "\n",
      "Features:  ['tvtot', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.09185570844179992\n",
      "Percent Type II errors: 0.1840833023428784\n",
      "\n",
      "Features:  ['tvtot', 'pplhlp', 'happy', 'agea']\n",
      "Percent Type I errors: 0.08925251022685013\n",
      "Percent Type II errors: 0.185198958720714\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'agea']\n",
      "Percent Type I errors: 0.07251766455931573\n",
      "Percent Type II errors: 0.1956117515805132\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.07474897731498699\n",
      "Percent Type II errors: 0.19375232428412048\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.04351059873558944\n",
      "Percent Type II errors: 0.22052807735217553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#None of the features besides age seem to consistently bring value. Let's try the same thing with a more gradual learning rate\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 3,\n",
    "         'loss': 'deviance',\n",
    "         'learning_rate': .5}\n",
    "\n",
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.04165117143919673\n",
      "Percent Type II errors: 0.198214949795463\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.03867608776496839\n",
      "Percent Type II errors: 0.20639642989959092\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.054667162513945704\n",
      "Percent Type II errors: 0.17999256229081442\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.04871699516548903\n",
      "Percent Type II errors: 0.19598363703979174\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.046113796950539236\n",
      "Percent Type II errors: 0.20044626255113426\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.05206396429899591\n",
      "Percent Type II errors: 0.20193380438824843\n",
      "\n",
      "Features:  ['happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.05057642246188174\n",
      "Percent Type II errors: 0.2045370026031982\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.06284864261807363\n",
      "Percent Type II errors: 0.20416511714391966\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.04537002603198215\n",
      "Percent Type II errors: 0.20899962811454073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#age still a winner, but the rest of the column combinations got worse. Le'ts try a lower value than default this time:\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 3,\n",
    "         'loss': 'deviance',\n",
    "         'learning_rate': .01}\n",
    "\n",
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.07549274823354407\n",
      "Percent Type II errors: 0.1788769059129788\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'agea']\n",
      "Percent Type I errors: 0.07400520639642989\n",
      "Percent Type II errors: 0.1833395314243213\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.08032725920416511\n",
      "Percent Type II errors: 0.1885459278542209\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.06396429899590926\n",
      "Percent Type II errors: 0.18482707326143547\n",
      "\n",
      "Features:  ['tvtot', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.07065823726292302\n",
      "Percent Type II errors: 0.17478616586091483\n",
      "\n",
      "Features:  ['pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.06545184083302343\n",
      "Percent Type II errors: 0.18445518780215694\n",
      "\n",
      "Features:  ['pplhlp', 'happy', 'agea']\n",
      "Percent Type I errors: 0.06917069542580885\n",
      "Percent Type II errors: 0.19933060617329862\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.06210487169951655\n",
      "Percent Type II errors: 0.19784306433618445\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.04722945332837486\n",
      "Percent Type II errors: 0.2246188174042395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Not really better than the default of .1 learning_rate. reset that to default, and do 75% subsampling\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 3,\n",
    "         'loss': 'deviance',\n",
    "         'learning_rate': .1,\n",
    "         'subsample': .75}\n",
    "\n",
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.0758646336928226\n",
      "Percent Type II errors: 0.1904053551506136\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'agea']\n",
      "Percent Type I errors: 0.07363332093715136\n",
      "Percent Type II errors: 0.18705838601710673\n",
      "\n",
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.07326143547787281\n",
      "Percent Type II errors: 0.18817404239494237\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'agea']\n",
      "Percent Type I errors: 0.07400520639642989\n",
      "Percent Type II errors: 0.1840833023428784\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'agea']\n",
      "Percent Type I errors: 0.06545184083302343\n",
      "Percent Type II errors: 0.20416511714391966\n",
      "\n",
      "Features:  ['pplfair', 'pplhlp', 'happy', 'agea']\n",
      "Percent Type I errors: 0.06582372629230197\n",
      "Percent Type II errors: 0.19226478244700632\n",
      "\n",
      "Features:  ['pplhlp', 'happy', 'agea']\n",
      "Percent Type I errors: 0.055782818891781334\n",
      "Percent Type II errors: 0.21197471178876906\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.06917069542580885\n",
      "Percent Type II errors: 0.189289698772778\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.04202305689847527\n",
      "Percent Type II errors: 0.20639642989959092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#50% subsampling?\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 3,\n",
    "         'loss': 'deviance',\n",
    "         'learning_rate': .1,\n",
    "         'subsample': .5}\n",
    "\n",
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.04685756786909632\n",
      "Percent Type II errors: 0.19263666790628486\n",
      "\n",
      "Features:  ['tvtot', 'pplfair', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.044626255113425065\n",
      "Percent Type II errors: 0.19375232428412048\n",
      "\n",
      "Features:  ['tvtot', 'pplhlp', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.039791744142804016\n",
      "Percent Type II errors: 0.2123465972480476\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'sclact', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.05057642246188174\n",
      "Percent Type II errors: 0.19970249163257717\n",
      "\n",
      "Features:  ['tvtot', 'happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.04537002603198215\n",
      "Percent Type II errors: 0.20490888806247676\n",
      "\n",
      "Features:  ['happy', 'sclmeet', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.04276682781703235\n",
      "Percent Type II errors: 0.20379323168464114\n",
      "\n",
      "Features:  ['happy', 'gndr', 'agea']\n",
      "Percent Type I errors: 0.056526589810338417\n",
      "Percent Type II errors: 0.19412420974339903\n",
      "\n",
      "Features:  ['happy', 'agea']\n",
      "Percent Type I errors: 0.04797322424693194\n",
      "Percent Type II errors: 0.21011528449237635\n",
      "\n",
      "Features:  ['agea']\n",
      "Percent Type I errors: 0.04351059873558944\n",
      "Percent Type II errors: 0.20639642989959092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#different criterion?\n",
    "params = {'n_estimators': 500,\n",
    "         'max_depth': 3,\n",
    "         'loss': 'deviance',\n",
    "         'learning_rate': .01,\n",
    "         'criterion': 'mse'}\n",
    "\n",
    "Y = df['partner'] -1\n",
    "it = df.drop(['cntry', 'idno', 'year', 'partner'], axis=1)\n",
    "while len(it.columns) >= 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(it, Y, test_size=0.33)\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "    print(\"Features: \" , [x for x in it.columns])\n",
    "    print((\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n'\n",
    "    ).format(test_tI_errors, test_tII_errors))\n",
    "    importances = list(clf.feature_importances_)\n",
    "    dropcol = importances.index(min(importances))\n",
    "    it = it.drop(it.columns[dropcol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

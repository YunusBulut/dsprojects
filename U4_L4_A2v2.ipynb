{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U4.L4.A2v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conditg/dsprojects/blob/master/U4_L4_A2v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ANyvVaO7uPzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "373f0cef-efad-431e-d42d-9c71e4622c78"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.corpus import gutenberg, stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r_qfnjFDuV4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function for standard text cleaning.\n",
        "def text_cleaner(text):\n",
        "    # Visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  Better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDWb9Ml9wSZl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and clean the data.\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# The Chapter indicator is idiosyncratic\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "    \n",
        "alice = text_cleaner(alice)\n",
        "persuasion = text_cleaner(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxZZ3GwEwUOm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse the cleaned novels. This can take a bit.\n",
        "nlp = spacy.load('en')\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4zGwfY-wXWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "98ef93fd-20af-4f2b-d362-6578034c7b77"
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "\n",
        "# Combine the sentences from the two novels into one data frame.\n",
        "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
        "print(sentences.shape)\n",
        "sentences.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5318, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "q9XxmZZmwa7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "3ce572eb-94ea-483b-bc7d-fac76b4c91db"
      },
      "cell_type": "code",
      "source": [
        "sentences.groupby(1).agg('count')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Austen</th>\n",
              "      <td>3649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Carroll</th>\n",
              "      <td>1669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "1            \n",
              "Austen   3649\n",
              "Carroll  1669"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "bjZXUbnuwds2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to create a list of the 2000 most common words.\n",
        "def bag_of_words(text):\n",
        "    \n",
        "    # Filter out punctuation and stop words.\n",
        "    allwords = [token.lemma_\n",
        "                for token in text\n",
        "                if not token.is_punct\n",
        "                and not token.is_stop]\n",
        "    \n",
        "    # Return the most common words.\n",
        "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
        "   \n",
        "# Set up the bags.\n",
        "alicewords = bag_of_words(alice_doc)\n",
        "persuasionwords = bag_of_words(persuasion_doc)\n",
        "\n",
        "# Combine bags to create a set of unique words.\n",
        "common_words = set(alicewords + persuasionwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xupa1kIUwmYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3735702a-94cd-400f-96d3-54e7c5de6825"
      },
      "cell_type": "code",
      "source": [
        "list(common_words)[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'occasionally'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "lrvP3CVrwrwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMyRv6W4xqvD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(vocabulary=common_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEIq4IbsyKeb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['text_sentence'] = sentences[0]\n",
        "df['text_source'] = sentences[1]\n",
        "#String version of the spacy objects\n",
        "df['str_sentence'] = [_.text for _ in df.text_sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMaOeFcHzENB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d13da788-f34d-4d33-f769-b5662d2c1787"
      },
      "cell_type": "code",
      "source": [
        "type(df.loc[5,'str_sentence'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "sv6pzk1GzEWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(df['str_sentence'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6LGyIH1IytE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2 =  pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfcseSz60m5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "c4312c00-f5c1-4127-b437-86e636e4f12a"
      },
      "cell_type": "code",
      "source": [
        "word_counts = pd.concat([df,df2], axis=1)\n",
        "print(word_counts.shape)\n",
        "word_counts.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5318, 3065)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "      <th>str_sentence</th>\n",
              "      <th>'s</th>\n",
              "      <th>-PRON-</th>\n",
              "      <th>1</th>\n",
              "      <th>`</th>\n",
              "      <th>a</th>\n",
              "      <th>abide</th>\n",
              "      <th>ability</th>\n",
              "      <th>...</th>\n",
              "      <th>you</th>\n",
              "      <th>you'd</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>youth</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zigzag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>Alice was beginning to get very tired of sitti...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>So she was considering in her own mind (as wel...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>Oh dear!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>I shall be late!'</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3065 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text_sentence text_source  \\\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll   \n",
              "1  (So, she, was, considering, in, her, own, mind...     Carroll   \n",
              "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll   \n",
              "3                                      (Oh, dear, !)     Carroll   \n",
              "4                         (I, shall, be, late, !, ')     Carroll   \n",
              "\n",
              "                                        str_sentence  's  -PRON-  1  `  a  \\\n",
              "0  Alice was beginning to get very tired of sitti...   0       0  0  0  0   \n",
              "1  So she was considering in her own mind (as wel...   0       0  0  0  0   \n",
              "2  There was nothing so VERY remarkable in that; ...   0       0  0  0  0   \n",
              "3                                           Oh dear!   0       0  0  0  0   \n",
              "4                                  I shall be late!'   0       0  0  0  0   \n",
              "\n",
              "   abide  ability   ...    you  you'd  young  your  yours  youth  zeal  \\\n",
              "0      0        0   ...      0      0      0     0      0      0     0   \n",
              "1      0        0   ...      0      0      0     0      0      0     0   \n",
              "2      0        0   ...      0      0      0     0      0      0     0   \n",
              "3      0        0   ...      0      0      0     0      0      0     0   \n",
              "4      0        0   ...      0      0      0     0      0      0     0   \n",
              "\n",
              "   zealand  zealous  zigzag  \n",
              "0        0        0       0  \n",
              "1        0        0       0  \n",
              "2        0        0       0  \n",
              "3        0        0       0  \n",
              "4        0        0       0  \n",
              "\n",
              "[5 rows x 3065 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "-Jzbg65p1Yig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1e325c8-2db3-4eba-c7c7-7de7cd46d06d"
      },
      "cell_type": "code",
      "source": [
        "#CHECK\n",
        "word_counts.loc[4,'str_sentence']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I shall be late!'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "JUNVH_Vv13Rc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e30da663-f21f-4359-ab00-ec03e8c7ef9f"
      },
      "cell_type": "code",
      "source": [
        "word_counts['shall'].head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    1\n",
              "Name: shall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "CcbE0Ozu2W_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "31b8b28d-2224-460b-ca2c-223a5f4dee0f"
      },
      "cell_type": "code",
      "source": [
        "word_counts['late'].head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    1\n",
              "Name: late, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "miNfmyC72oVc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Forest Attempt"
      ]
    },
    {
      "metadata": {
        "id": "Gfl8WpSa2sDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6d845eb0-a0c6-427b-bffc-7adb8509c818"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source', 'str_sentence'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)\n",
        "train = rfc.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.9893416927899686\n",
            "\n",
            "Test set score: 0.8477443609022557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eBREPzTs6vIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "J1GOtYf-29lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "205604e8-d81d-46ac-a743-37eebfe0b566"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3190, 3062) (3190,)\n",
            "Training set score: 0.9545454545454546\n",
            "\n",
            "Test set score: 0.8843984962406015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KZ4YEJFz6rL7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Booster"
      ]
    },
    {
      "metadata": {
        "id": "CJB9Ujf93WzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "67b6df45-02bf-4772-e296-7f1b0f6830f6"
      },
      "cell_type": "code",
      "source": [
        "clf = ensemble.GradientBoostingClassifier()\n",
        "train = clf.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.8642633228840125\n",
            "\n",
            "Test set score: 0.8529135338345865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AE4Bx8Ns6_0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#New Inputs"
      ]
    },
    {
      "metadata": {
        "id": "VhB3NWQ53a2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f539118-2004-4366-ff20-0cdbc7f979fc"
      },
      "cell_type": "code",
      "source": [
        "# Clean the Emma data.\n",
        "emma = gutenberg.raw('austen-emma.txt')\n",
        "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
        "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
        "emma = text_cleaner(emma)\n",
        "print(emma[:100])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_V9tZZq17B8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse our cleaned data.\n",
        "emma_doc = nlp(emma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJDVeob37DeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
        "\n",
        "# Emma is quite long, let's cut it down to the same length as Alice.\n",
        "emma_sents = emma_sents[0:len(alice_sents)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yIV3ajV17FHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b78b3c1e-8f3b-426f-c336-e040f685d5ea"
      },
      "cell_type": "code",
      "source": [
        "emma_sentences = pd.DataFrame(emma_sents)\n",
        "emma_sentences.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Emma, Woodhouse, ,, handsome, ,, clever, ,, a...</td>\n",
              "      <td>Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
              "      <td>Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
              "      <td>Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
              "      <td>Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Between, _, them)</td>\n",
              "      <td>Austen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0       1\n",
              "0  (Emma, Woodhouse, ,, handsome, ,, clever, ,, a...  Austen\n",
              "1  (She, was, the, youngest, of, the, two, daught...  Austen\n",
              "2  (Her, mother, had, died, too, long, ago, for, ...  Austen\n",
              "3  (Sixteen, years, had, Miss, Taylor, been, in, ...  Austen\n",
              "4                                 (Between, _, them)  Austen"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "1Wrpdouh7MWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emma = pd.DataFrame()\n",
        "emma['text_sentence'] = emma_sentences[0]\n",
        "emma['text_source'] = emma_sentences[1]\n",
        "#String version of the spacy objects\n",
        "emma['str_sentence'] = [_.text for _ in emma.text_sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zlXuOS7P9azv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(emma['str_sentence'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FymvR5qZ9f2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2 =  pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivoBpXwP9naB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c1c3da1e-ecd4-49f5-d15c-3bc25c6433bb"
      },
      "cell_type": "code",
      "source": [
        "emma_bow = pd.concat([emma,df2], axis=1)\n",
        "print(emma_bow.shape)\n",
        "emma_bow.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1669, 3065)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "      <th>str_sentence</th>\n",
              "      <th>'s</th>\n",
              "      <th>-PRON-</th>\n",
              "      <th>1</th>\n",
              "      <th>`</th>\n",
              "      <th>a</th>\n",
              "      <th>abide</th>\n",
              "      <th>ability</th>\n",
              "      <th>...</th>\n",
              "      <th>you</th>\n",
              "      <th>you'd</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>youth</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zigzag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Emma, Woodhouse, ,, handsome, ,, clever, ,, a...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>Emma Woodhouse, handsome, clever, and rich, wi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>She was the youngest of the two daughters of a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>Her mother had died too long ago for her to ha...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>Sixteen years had Miss Taylor been in Mr. Wood...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Between, _, them)</td>\n",
              "      <td>Austen</td>\n",
              "      <td>Between _them</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3065 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text_sentence text_source  \\\n",
              "0  (Emma, Woodhouse, ,, handsome, ,, clever, ,, a...      Austen   \n",
              "1  (She, was, the, youngest, of, the, two, daught...      Austen   \n",
              "2  (Her, mother, had, died, too, long, ago, for, ...      Austen   \n",
              "3  (Sixteen, years, had, Miss, Taylor, been, in, ...      Austen   \n",
              "4                                 (Between, _, them)      Austen   \n",
              "\n",
              "                                        str_sentence  's  -PRON-  1  `  a  \\\n",
              "0  Emma Woodhouse, handsome, clever, and rich, wi...   0       0  0  0  0   \n",
              "1  She was the youngest of the two daughters of a...   0       0  0  0  0   \n",
              "2  Her mother had died too long ago for her to ha...   0       0  0  0  0   \n",
              "3  Sixteen years had Miss Taylor been in Mr. Wood...   0       0  0  0  0   \n",
              "4                                      Between _them   0       0  0  0  0   \n",
              "\n",
              "   abide  ability   ...    you  you'd  young  your  yours  youth  zeal  \\\n",
              "0      0        0   ...      0      0      0     0      0      0     0   \n",
              "1      0        0   ...      0      0      0     0      0      0     0   \n",
              "2      0        0   ...      0      0      0     0      0      0     0   \n",
              "3      0        0   ...      0      0      0     0      0      0     0   \n",
              "4      0        0   ...      0      0      0     0      0      0     0   \n",
              "\n",
              "   zealand  zealous  zigzag  \n",
              "0        0        0       0  \n",
              "1        0        0       0  \n",
              "2        0        0       0  \n",
              "3        0        0       0  \n",
              "4        0        0       0  \n",
              "\n",
              "[5 rows x 3065 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "YA9gFZhB9xDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c34c0e5b-2449-4c9d-dd34-8b05a942d98b"
      },
      "cell_type": "code",
      "source": [
        "# Combine the Emma sentence data with the Alice data from the test set.\n",
        "X_Emma_test = np.concatenate((\n",
        "    X_train[y_train[y_train=='Carroll'].index],\n",
        "    emma_bow.drop(['text_sentence','text_source', 'str_sentence'], 1)\n",
        "), axis=0)\n",
        "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
        "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
        "\n",
        "# Model.\n",
        "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
        "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
        "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set score: 0.6923937360178971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>Austen</th>\n",
              "      <th>Carroll</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Austen</th>\n",
              "      <td>1536</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Carroll</th>\n",
              "      <td>692</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    Austen  Carroll\n",
              "row_0                   \n",
              "Austen     1536      133\n",
              "Carroll     692      321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZS74AU1-VHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Challenge 0:\n",
        "\n",
        "Recall that the logistic regression model's best performance on the test set was 93%.  See what you can do to improve performance.  Suggested avenues of investigation include: Other modeling techniques (SVM?), making more features that take advantage of the spaCy information (include grammar, phrases, POS, etc), making sentence-level features (number of words, amount of punctuation), or including contextual information (length of previous and next sentences, words repeated from one sentence to the next, etc), and anything else your heart desires.  Make sure to design your models on the test set, or use cross_validation with multiple folds, and see if you can get accuracy above 90%.  "
      ]
    },
    {
      "metadata": {
        "id": "QEUQFjm699Xf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d875f57f-c449-4fd4-da24-c281d21054cf"
      },
      "cell_type": "code",
      "source": [
        "#Baseline\n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3190, 3062) (3190,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.9545454545454546\n",
            "\n",
            "Test set score: 0.8843984962406015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mSRwk5QA_kxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47fcb92f-6632-42a6-908e-a46c0de820b7"
      },
      "cell_type": "code",
      "source": [
        "len(lr.coef_[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "72EmfYNkJG-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29c9c5aa-6a15-40ae-a803-7b59fa3f9a8b"
      },
      "cell_type": "code",
      "source": [
        "#How many of those are actually over zero?\n",
        "len([x for x in lr.coef_[0] if x > 0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "k-z-Ee2fFw_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aa9f1793-3957-4b6a-c206-f3008dd258e6"
      },
      "cell_type": "code",
      "source": [
        "print(word_counts.loc[0,'text_sentence'])\n",
        "print([x.pos_ for x in word_counts.loc[0,'text_sentence']])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
            "['PROPN', 'VERB', 'VERB', 'PART', 'VERB', 'ADV', 'ADJ', 'ADP', 'VERB', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT', 'CCONJ', 'ADP', 'VERB', 'NOUN', 'PART', 'VERB', 'PUNCT', 'ADV', 'CCONJ', 'ADV', 'PRON', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'VERB', 'PUNCT', 'CCONJ', 'PRON', 'VERB', 'DET', 'NOUN', 'CCONJ', 'NOUN', 'ADP', 'PRON', 'PUNCT', 'PUNCT', 'CCONJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT', 'PUNCT', 'VERB', 'PROPN', 'PUNCT', 'ADP', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rviQWlwhCvhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add counts of key types\n",
        "word_counts['sent_len'] = [len(x) for x in word_counts.str_sentence]\n",
        "word_counts['cnt_verbs'] = [sum([1 for x in j if x.pos_ == 'VERB']) for j in word_counts.text_sentence]\n",
        "word_counts['cnt_adj'] = [sum([1 for x in j if x.pos_ == 'ADJ']) for j in word_counts.text_sentence]\n",
        "word_counts['cnt_prop'] = [sum([1 for x in j if x.pos_ == 'PROPN']) for j in word_counts.text_sentence]\n",
        "word_counts['cnt_punct'] = [sum([1 for x in j if x.pos_ == 'PUNCT']) for j in word_counts.text_sentence]\n",
        "word_counts['cnt_adv'] = [sum([1 for x in j if x.pos_ == 'ADV']) for j in word_counts.text_sentence]\n",
        "word_counts['cnt_nouns'] = [sum([1 for x in j if x.pos_ == 'NOUN']) for j in word_counts.text_sentence]\n",
        "word_counts['crude_sentiment'] = [j.sentiment for j in word_counts.text_sentence]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HSCaAj0Fhcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Redefine train/test splits\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source',\n",
        "                               'str_sentence'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJCUz6tiIo84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4aa86a9e-2d5c-4621-b933-e165e0c4b8bb"
      },
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3190, 3070) (3190,)\n",
            "Training set score: 0.9554858934169279\n",
            "\n",
            "Test set score: 0.8956766917293233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zggebfXwIsEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0010a0e5-502d-4cef-fb22-ad8e443e5da5"
      },
      "cell_type": "code",
      "source": [
        "#Interestingly, th added columns reduces how many features are used by Lasso Regression\n",
        "len([x for x in lr.coef_[0] if x > 0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "HEfTAtqhNnvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06d8a715-04dc-4bab-ef2d-c3370f63b465"
      },
      "cell_type": "code",
      "source": [
        "len(lr.coef_[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3070"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "5XVZ8tHMRE9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "669149d3-a1d5-4262-a1ab-204c126a2b21"
      },
      "cell_type": "code",
      "source": [
        "len(word_counts.columns[3:])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3070"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "FDhNlwcURNfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a82cae4-4add-4185-d1cf-d2073c634758"
      },
      "cell_type": "code",
      "source": [
        "#Remove useless columns, then try one of the other models\n",
        "colsToUse = []\n",
        "\n",
        "for i, col in enumerate(word_counts.columns[3:]):\n",
        "  if lr.coef_[0][i] >0:\n",
        "    colsToUse.append(col)\n",
        "#confirm:\n",
        "len(colsToUse)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "G7sYaKjjR_Wx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Redefine train/test splits\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts[colsToUse])\n",
        "\n",
        "X_shorttrain, X_shorttest, y_shorttrain, y_shorttest = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Nv7pVUPSIc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eae5b68f-2fe7-45d4-d054-fec6f167400e"
      },
      "cell_type": "code",
      "source": [
        "clf = ensemble.GradientBoostingClassifier()\n",
        "train = clf.fit(X_shorttrain, y_shorttrain)\n",
        "\n",
        "print('Training set score:', clf.score(X_shorttrain, y_shorttrain))\n",
        "print('\\nTest set score:', clf.score(X_shorttest, y_shorttest))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.8677115987460815\n",
            "\n",
            "Test set score: 0.8491541353383458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k9a-RJoVTCEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Analysis 0:\n",
        "By adding features related to the types of tokens in each span, Logistic Regression with Lasso regularization was able to get 89.6% accuracy on a test set, continuing to outperform other models types with this dataset"
      ]
    },
    {
      "metadata": {
        "id": "9PXV6JwpTYmf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Challenge 1:\n",
        "Find out whether your new model is good at identifying Alice in Wonderland vs any other work, Persuasion vs any other work, or Austen vs any other work.  This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it."
      ]
    },
    {
      "metadata": {
        "id": "gCfs51EsSKdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3ddc232-770d-49d7-91ee-3152a958fe0c"
      },
      "cell_type": "code",
      "source": [
        "print(gutenberg.fileids())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Je3ZenH4SNBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29d442bb-b402-46c8-c162-bd1c12007036"
      },
      "cell_type": "code",
      "source": [
        "#Can this differentiate Paradise from Alice in Wonderland?\n",
        "\n",
        "md = gutenberg.raw('milton-paradise.txt')\n",
        "md = re.sub(r'VOLUME \\w+', '', md)\n",
        "md = re.sub(r'CHAPTER \\w+', '', md)\n",
        "md = text_cleaner(md)\n",
        "print(type(md))\n",
        "print(md[:100])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "Book I Of Man's first disobedience, and the fruit Of that forbidden tree whose mortal taste Brought \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jkh4HoE3VZOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse our cleaned data\n",
        "\n",
        "# This book  is quite long, let's cut it down to the same length as Alice.\n",
        "mdabb = md[0:len(alice)]\n",
        "md_doc = nlp(mdabb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FJMqJtTCV2mK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md_sents = [[sent, \"Milton\"] for sent in md_doc.sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6gfEHPZWFE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdf = pd.DataFrame(md_sents)\n",
        "mdf2 = pd.DataFrame()\n",
        "mdf2['text_sentence'] = mdf[0]\n",
        "mdf2['text_source'] = mdf[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8yzh084Xk_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#String version of the spacy objects\n",
        "mdf2['str_sentence'] = [_.text for _ in mdf2.text_sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36UmDDY2gNLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(mdf2['str_sentence'])\n",
        "df2 =  pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19S80176YTBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8dd64a3a-5f87-4b94-84a8-279100e3786e"
      },
      "cell_type": "code",
      "source": [
        "para_bow = pd.concat([mdf2,df2], axis=1)\n",
        "print(para_bow.shape)\n",
        "para_bow.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(852, 3065)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "      <th>str_sentence</th>\n",
              "      <th>'s</th>\n",
              "      <th>-PRON-</th>\n",
              "      <th>1</th>\n",
              "      <th>`</th>\n",
              "      <th>a</th>\n",
              "      <th>abide</th>\n",
              "      <th>ability</th>\n",
              "      <th>...</th>\n",
              "      <th>you</th>\n",
              "      <th>you'd</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>youth</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zigzag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Book, I, Of, Man, 's, first, disobedience, ,,...</td>\n",
              "      <td>Milton</td>\n",
              "      <td>Book I Of Man's first disobedience, and the fr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(And, chiefly, thou, ,, O, Spirit, ,, that, do...</td>\n",
              "      <td>Milton</td>\n",
              "      <td>And chiefly thou, O Spirit, that dost prefer B...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Say, first, for, Heaven, hides, nothing, from...</td>\n",
              "      <td>Milton</td>\n",
              "      <td>Say first for Heaven hides nothing from thy vi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Who, first, seduced, them, to, that, foul, re...</td>\n",
              "      <td>Milton</td>\n",
              "      <td>Who first seduced them to that foul revolt?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Th, ', infernal, Serpent, ;, he, it, was, who...</td>\n",
              "      <td>Milton</td>\n",
              "      <td>Th' infernal Serpent; he it was whose guile, S...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3065 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text_sentence text_source  \\\n",
              "0  (Book, I, Of, Man, 's, first, disobedience, ,,...      Milton   \n",
              "1  (And, chiefly, thou, ,, O, Spirit, ,, that, do...      Milton   \n",
              "2  (Say, first, for, Heaven, hides, nothing, from...      Milton   \n",
              "3  (Who, first, seduced, them, to, that, foul, re...      Milton   \n",
              "4  (Th, ', infernal, Serpent, ;, he, it, was, who...      Milton   \n",
              "\n",
              "                                        str_sentence  's  -PRON-  1  `  a  \\\n",
              "0  Book I Of Man's first disobedience, and the fr...   0       0  0  0  0   \n",
              "1  And chiefly thou, O Spirit, that dost prefer B...   0       0  0  0  0   \n",
              "2  Say first for Heaven hides nothing from thy vi...   0       0  0  0  0   \n",
              "3        Who first seduced them to that foul revolt?   0       0  0  0  0   \n",
              "4  Th' infernal Serpent; he it was whose guile, S...   0       0  0  0  0   \n",
              "\n",
              "   abide  ability   ...    you  you'd  young  your  yours  youth  zeal  \\\n",
              "0      0        0   ...      0      0      0     0      0      0     0   \n",
              "1      0        0   ...      0      0      0     0      0      0     0   \n",
              "2      0        0   ...      0      0      0     0      0      0     0   \n",
              "3      0        0   ...      0      0      0     0      0      0     0   \n",
              "4      0        0   ...      0      0      0     0      0      0     0   \n",
              "\n",
              "   zealand  zealous  zigzag  \n",
              "0        0        0       0  \n",
              "1        0        0       0  \n",
              "2        0        0       0  \n",
              "3        0        0       0  \n",
              "4        0        0       0  \n",
              "\n",
              "[5 rows x 3065 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "Vnuvpahbj-D7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "97f80324-163e-44da-922f-66cc74fdc734"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['text_sentence'] = sentences[0]\n",
        "df['text_source'] = sentences[1]\n",
        "#String version of the spacy objects\n",
        "df['str_sentence'] = [_.text for _ in df.text_sentence]\n",
        "X = vectorizer.fit_transform(df['str_sentence'])\n",
        "df2 =  pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "word_counts = pd.concat([df,df2], axis=1)\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source',\n",
        "                               'str_sentence'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)\n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "51yX-dgydwis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0eac35b1-82e3-4028-f947-1d3fbc7077d0"
      },
      "cell_type": "code",
      "source": [
        "# Combine the paradise sentence data with the Alice data from the test set.\n",
        "X_para_test = np.concatenate((\n",
        "    X_train[y_train[y_train=='Carroll'].index],\n",
        "    para_bow.drop(['text_sentence','text_source', 'str_sentence'], 1)\n",
        "), axis=0)\n",
        "y_para_test = pd.concat([y_train[y_train=='Carroll'],\n",
        "                         pd.Series(['Milton'] * para_bow.shape[0])])\n",
        "\n",
        "# Model.\n",
        "print('\\nTest set score:', lr.score(X_para_test, y_para_test))\n",
        "lr_para_predicted = lr.predict(X_para_test)\n",
        "pd.crosstab(y_para_test, lr_para_predicted)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set score: 0.17211796246648794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>Austen</th>\n",
              "      <th>Carroll</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Carroll</th>\n",
              "      <td>692</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Milton</th>\n",
              "      <td>693</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    Austen  Carroll\n",
              "row_0                   \n",
              "Carroll     692      321\n",
              "Milton      693      159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "6X0_hifIk73P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This classifier appears to be better at identifying Austen than it is at differentiating Carroll."
      ]
    },
    {
      "metadata": {
        "id": "Av2__X-zjUow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}